{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **The seventh in-class-exercise (40 points in total, 10/20/2021)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question description: Please use the text corpus you collected in your last in-class-exercise for this exercise. Perform the following tasks:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) (15 points) Generate K topics by using LDA, the number of topics K should be decided by the coherence score, then summarize what are the topics. You may refer the code here: \n",
    "\n",
    "https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "# Write your code here\n",
    "# pip install pyLDAvis\n",
    "# pip install gensim\n",
    "# pip install spacy\n",
    "\n",
    "import nltk\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models import LsiModel\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "\n",
    "\n",
    "\n",
    "# Setting up nltk\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Reviews.CSV\") # Import the Reviews.CSV as pandas dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cleaning the reviews\n",
    "data = df.Reviews.values.tolist() # Convert each review to list\n",
    "data = [re.sub('\\s+', ' ', sentence) for sentence in data] # remose the line breakers\n",
    "data = [re.sub(\"\\'\",\" \", sentence) for sentence in data] # remocve the \\'\n",
    "\n",
    "def sent_to_words(reviews):\n",
    "    \"\"\"\n",
    "    Input: sentence--> string\n",
    "    Function: Tokenize the sentence and remove punctuations\n",
    "    Output: tokenize and clean reviews\n",
    "    \"\"\"\n",
    "    sentence = []\n",
    "    for review in reviews:\n",
    "        sentence.append(gensim.utils.simple_preprocess(str(review).encode('utf-8'), deacc=True))  # deacc=True removes punctuations\n",
    "    return sentence\n",
    "tokenize_reviews = list(sent_to_words(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## bigram and trigam mmodels \n",
    "bigram = gensim.models.Phrases(tokenize_reviews, min_count=5, threshold=100) # creat bigram phrases\n",
    "bigram_model = gensim.models.phrases.Phraser(bigram) # bigram model\n",
    "trigram_model = gensim.models.phrases.Phraser(gensim.models.Phrases(bigram[tokenize_reviews], threshold=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(reviews): \n",
    "    \"\"\"\n",
    "    Input: list of lists of reviews\n",
    "    Func: remove all stopwords\n",
    "    Output: tokenize reviews without stop words\n",
    "    \"\"\"\n",
    "    return [[word for word in simple_preprocess(str(review)) if word not in stop_words] for review in reviews]\n",
    "\n",
    "def make_bigrams(reviews):\n",
    "    \"\"\"\n",
    "    Input: tokenize reviews\n",
    "    Func: make bigrams\n",
    "    Output: bigrams of reviews\n",
    "    \"\"\"\n",
    "    return [bigram_model[review] for review in reviews]\n",
    "\n",
    "def make_trigrams(reviews):\n",
    "    \"\"\"\n",
    "    Input: tokenize reviews\n",
    "    Func: make trigrams\n",
    "    Output: trigrams of bigram reviews\n",
    "    \"\"\"\n",
    "    return [trigram_model[bigram_model[review]] for review in reviews]\n",
    "\n",
    "def lemmatization(reviews, allowed=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"\n",
    "    Input: tokenize bigram reviews\n",
    "    Func: return only Noun, adj, verb, adverbs\n",
    "    Output: nouns, adj, verb, adv of reviews\n",
    "    \"\"\"\n",
    "    output_reviews= []\n",
    "    for sent in reviews:\n",
    "        review = nlp(\" \".join(sent)) \n",
    "        output_reviews.append([token.lemma_ for token in review if token.pos_ in allowed])\n",
    "    return output_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bigrame_reviews = make_bigrams(remove_stopwords(tokenize_reviews)) # take bigram of the Reviews without stopwords\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner']) # initiaize the nlp english model\n",
    "\n",
    "lemmatize_reviews = lemmatization(bigrame_reviews, ['NOUN', 'ADJ', 'VERB', 'ADV']) # nouns, adj, verb, adv of reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "id2word = corpora.Dictionary(lemmatize_reviews) # Create Dictionary\n",
    "\n",
    "corpus = [id2word.doc2bow(review) for review in lemmatize_reviews] # freq of words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LDA model\n",
    "LDA_model = gensim.models.ldamodel.LdaModel(corpus=corpus, id2word=id2word, num_topics=20, random_state=100, update_every=1,\n",
    "                                            chunksize=100, passes=10, alpha='auto', per_word_topics=True)\n",
    "review_lda = LDA_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity:  -10.742683907454639\n",
      "Coherence Score:  0.42085161661501297\n"
     ]
    }
   ],
   "source": [
    "print('Perplexity: ', LDA_model.log_perplexity(corpus))  # Compute Perplexity and print it\n",
    "coherence_model_lda = CoherenceModel(model=LDA_model, texts=lemmatize_reviews, dictionary=id2word, coherence='c_v') #initilize coherence model\n",
    "coherence_lda = coherence_model_lda.get_coherence() #get cohernece score\n",
    "print('Coherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic 01</th>\n",
       "      <th>Topic 02</th>\n",
       "      <th>Topic 03</th>\n",
       "      <th>Topic 04</th>\n",
       "      <th>Topic 05</th>\n",
       "      <th>Topic 06</th>\n",
       "      <th>Topic 07</th>\n",
       "      <th>Topic 08</th>\n",
       "      <th>Topic 09</th>\n",
       "      <th>Topic 10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>familiar</td>\n",
       "      <td>movie</td>\n",
       "      <td>sort</td>\n",
       "      <td>hear</td>\n",
       "      <td>middle</td>\n",
       "      <td>forgettable</td>\n",
       "      <td>reunion</td>\n",
       "      <td>battle</td>\n",
       "      <td>film</td>\n",
       "      <td>steal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>serious</td>\n",
       "      <td>marvel</td>\n",
       "      <td>forward</td>\n",
       "      <td>dweller</td>\n",
       "      <td>direct</td>\n",
       "      <td>personal</td>\n",
       "      <td>lens</td>\n",
       "      <td>open</td>\n",
       "      <td>character</td>\n",
       "      <td>backstory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pacing</td>\n",
       "      <td>good</td>\n",
       "      <td>ability</td>\n",
       "      <td>train</td>\n",
       "      <td>bear</td>\n",
       "      <td>version</td>\n",
       "      <td>estimate</td>\n",
       "      <td>explain</td>\n",
       "      <td>scene</td>\n",
       "      <td>struggle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>see</td>\n",
       "      <td>visually_stunning</td>\n",
       "      <td>fast</td>\n",
       "      <td>awe</td>\n",
       "      <td>night</td>\n",
       "      <td>indian</td>\n",
       "      <td>ta_lo</td>\n",
       "      <td>well</td>\n",
       "      <td>gang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>flaw</td>\n",
       "      <td>watch</td>\n",
       "      <td>praise</td>\n",
       "      <td>sympathy</td>\n",
       "      <td>going</td>\n",
       "      <td>insane</td>\n",
       "      <td>drench</td>\n",
       "      <td>beautifully</td>\n",
       "      <td>great</td>\n",
       "      <td>stick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>finish</td>\n",
       "      <td>action</td>\n",
       "      <td>silly</td>\n",
       "      <td>gate</td>\n",
       "      <td>overrate</td>\n",
       "      <td>overshadow</td>\n",
       "      <td>desperately</td>\n",
       "      <td>acting</td>\n",
       "      <td>fight</td>\n",
       "      <td>dc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>difference</td>\n",
       "      <td>new</td>\n",
       "      <td>typical</td>\n",
       "      <td>assassin</td>\n",
       "      <td>surpass</td>\n",
       "      <td>otherwise</td>\n",
       "      <td>farm</td>\n",
       "      <td>simple</td>\n",
       "      <td>story</td>\n",
       "      <td>extraordinary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>comedic_time</td>\n",
       "      <td>superhero</td>\n",
       "      <td>motivation</td>\n",
       "      <td>escape</td>\n",
       "      <td>left</td>\n",
       "      <td>old_school</td>\n",
       "      <td>entrie</td>\n",
       "      <td>break</td>\n",
       "      <td>really</td>\n",
       "      <td>catch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>exact</td>\n",
       "      <td>amazing</td>\n",
       "      <td>tone</td>\n",
       "      <td>pendant</td>\n",
       "      <td>household</td>\n",
       "      <td>generation</td>\n",
       "      <td>god</td>\n",
       "      <td>reference</td>\n",
       "      <td>feel</td>\n",
       "      <td>today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>wise</td>\n",
       "      <td>make</td>\n",
       "      <td>develop</td>\n",
       "      <td>destruction</td>\n",
       "      <td>praise</td>\n",
       "      <td>authentic</td>\n",
       "      <td>stoic</td>\n",
       "      <td>leung</td>\n",
       "      <td>mcu</td>\n",
       "      <td>refreshing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>overdone</td>\n",
       "      <td>mcu</td>\n",
       "      <td>consequence</td>\n",
       "      <td>elder</td>\n",
       "      <td>typical</td>\n",
       "      <td>flying_dragon</td>\n",
       "      <td>ye</td>\n",
       "      <td>certainly</td>\n",
       "      <td>also</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>watchable</td>\n",
       "      <td>fan</td>\n",
       "      <td>unique</td>\n",
       "      <td>iron</td>\n",
       "      <td>develop</td>\n",
       "      <td>slay</td>\n",
       "      <td>forever</td>\n",
       "      <td>potential</td>\n",
       "      <td>get</td>\n",
       "      <td>portrayal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>model</td>\n",
       "      <td>story</td>\n",
       "      <td>excited</td>\n",
       "      <td>food</td>\n",
       "      <td>special</td>\n",
       "      <td>typical</td>\n",
       "      <td>album</td>\n",
       "      <td>ton</td>\n",
       "      <td>much</td>\n",
       "      <td>significant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>notable</td>\n",
       "      <td>visual</td>\n",
       "      <td>chance</td>\n",
       "      <td>grifter</td>\n",
       "      <td>continue</td>\n",
       "      <td>important</td>\n",
       "      <td>curate</td>\n",
       "      <td>skill</td>\n",
       "      <td>make</td>\n",
       "      <td>search</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>rapid</td>\n",
       "      <td>definitely</td>\n",
       "      <td>charisma</td>\n",
       "      <td>property</td>\n",
       "      <td>guess</td>\n",
       "      <td>brief</td>\n",
       "      <td>useful</td>\n",
       "      <td>tale</td>\n",
       "      <td>go</td>\n",
       "      <td>highly_recommende</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>slightly</td>\n",
       "      <td>joke</td>\n",
       "      <td>wish</td>\n",
       "      <td>outlaw</td>\n",
       "      <td>conclusion</td>\n",
       "      <td>kill</td>\n",
       "      <td>biopic</td>\n",
       "      <td>twist</td>\n",
       "      <td>action</td>\n",
       "      <td>ordinary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>pace</td>\n",
       "      <td>origin</td>\n",
       "      <td>basic</td>\n",
       "      <td>originality</td>\n",
       "      <td>anyway</td>\n",
       "      <td>news</td>\n",
       "      <td>bollywood</td>\n",
       "      <td>obviously</td>\n",
       "      <td>end</td>\n",
       "      <td>villian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>compare</td>\n",
       "      <td>sequence</td>\n",
       "      <td>thinking</td>\n",
       "      <td>nefarious</td>\n",
       "      <td>rather</td>\n",
       "      <td>flick</td>\n",
       "      <td>positively</td>\n",
       "      <td>animal</td>\n",
       "      <td>time</td>\n",
       "      <td>partner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ancient</td>\n",
       "      <td>different</td>\n",
       "      <td>blockbuster</td>\n",
       "      <td>seldom</td>\n",
       "      <td>slightly</td>\n",
       "      <td>care</td>\n",
       "      <td>passionate</td>\n",
       "      <td>proper</td>\n",
       "      <td>first</td>\n",
       "      <td>navigate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>arc</td>\n",
       "      <td>year</td>\n",
       "      <td>loyal</td>\n",
       "      <td>infamous</td>\n",
       "      <td>appreciate</td>\n",
       "      <td>series</td>\n",
       "      <td>million</td>\n",
       "      <td>realm</td>\n",
       "      <td>even</td>\n",
       "      <td>trademark</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Topic 01    Topic 02           Topic 03     Topic 04    Topic 05  \\\n",
       "0       familiar       movie               sort         hear      middle   \n",
       "1        serious      marvel            forward      dweller      direct   \n",
       "2         pacing        good            ability        train        bear   \n",
       "3            min         see  visually_stunning         fast         awe   \n",
       "4           flaw       watch             praise     sympathy       going   \n",
       "5         finish      action              silly         gate    overrate   \n",
       "6     difference         new            typical     assassin     surpass   \n",
       "7   comedic_time   superhero         motivation       escape        left   \n",
       "8          exact     amazing               tone      pendant   household   \n",
       "9           wise        make            develop  destruction      praise   \n",
       "10      overdone         mcu        consequence        elder     typical   \n",
       "11     watchable         fan             unique         iron     develop   \n",
       "12         model       story            excited         food     special   \n",
       "13       notable      visual             chance      grifter    continue   \n",
       "14         rapid  definitely           charisma     property       guess   \n",
       "15      slightly        joke               wish       outlaw  conclusion   \n",
       "16          pace      origin              basic  originality      anyway   \n",
       "17       compare    sequence           thinking    nefarious      rather   \n",
       "18       ancient   different        blockbuster       seldom    slightly   \n",
       "19           arc        year              loyal     infamous  appreciate   \n",
       "\n",
       "         Topic 06     Topic 07     Topic 08   Topic 09           Topic 10  \n",
       "0     forgettable      reunion       battle       film              steal  \n",
       "1        personal         lens         open  character          backstory  \n",
       "2         version     estimate      explain      scene           struggle  \n",
       "3           night       indian        ta_lo       well               gang  \n",
       "4          insane       drench  beautifully      great              stick  \n",
       "5      overshadow  desperately       acting      fight                 dc  \n",
       "6       otherwise         farm       simple      story      extraordinary  \n",
       "7      old_school       entrie        break     really              catch  \n",
       "8      generation          god    reference       feel              today  \n",
       "9       authentic        stoic        leung        mcu         refreshing  \n",
       "10  flying_dragon           ye    certainly       also              adult  \n",
       "11           slay      forever    potential        get          portrayal  \n",
       "12        typical        album          ton       much        significant  \n",
       "13      important       curate        skill       make             search  \n",
       "14          brief       useful         tale         go  highly_recommende  \n",
       "15           kill       biopic        twist     action           ordinary  \n",
       "16           news    bollywood    obviously        end            villian  \n",
       "17          flick   positively       animal       time            partner  \n",
       "18           care   passionate       proper      first           navigate  \n",
       "19         series      million        realm       even          trademark  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check and \n",
    "def get_lda_topics(model, num_topics):\n",
    "    \"\"\"\n",
    "    Input: LDA model, required topics\n",
    "    Func: create a dataframe of topics\n",
    "    Output: Pandas data frame\n",
    "    \"\"\"\n",
    "    word_dict = {}\n",
    "    for i in range(num_topics):\n",
    "        words = model.show_topic(i, topn = 20)\n",
    "        word_dict['Topic ' + '{:02d}'.format(i+1)] = [i[0] for i in words]\n",
    "    return pd.DataFrame(word_dict)\n",
    "\n",
    "get_lda_topics(LDA_model, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "    Dictionary of words freq --> dict\n",
    "    corpus of words --> list\n",
    "    reviews --> list\n",
    "    limit --> int\n",
    "    start --> int\n",
    "    step --> int\n",
    "    Func: find the coherence score for each set of topic numbers\n",
    "    Output: \n",
    "    model_list --> list: list of models\n",
    "    coherence_values --> float: score of coherence\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.LdaModel(corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=lemmatize_reviews, start=1, limit=20, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics Number= 1  has Coherence Value of 0.3057\n",
      "Topics Number= 2  has Coherence Value of 0.3168\n",
      "Topics Number= 3  has Coherence Value of 0.3088\n",
      "Topics Number= 4  has Coherence Value of 0.3073\n",
      "Topics Number= 5  has Coherence Value of 0.3123\n",
      "Topics Number= 6  has Coherence Value of 0.3058\n",
      "Topics Number= 7  has Coherence Value of 0.3109\n",
      "Topics Number= 8  has Coherence Value of 0.3162\n",
      "Topics Number= 9  has Coherence Value of 0.312\n",
      "Topics Number= 10  has Coherence Value of 0.3167\n",
      "Topics Number= 11  has Coherence Value of 0.3143\n",
      "Topics Number= 12  has Coherence Value of 0.311\n",
      "Topics Number= 13  has Coherence Value of 0.3092\n",
      "Topics Number= 14  has Coherence Value of 0.3137\n",
      "Topics Number= 15  has Coherence Value of 0.3024\n",
      "Topics Number= 16  has Coherence Value of 0.3039\n",
      "Topics Number= 17  has Coherence Value of 0.3094\n",
      "Topics Number= 18  has Coherence Value of 0.3138\n",
      "Topics Number= 19  has Coherence Value of 0.317\n"
     ]
    }
   ],
   "source": [
    "for model, cv in zip(range(1, 20, 1), coherence_values):\n",
    "    print(\"Topics Number=\", model, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum value of coherence for ascending order is: 0.3152\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Maximum value of coherence for ascending order is: 0.3152\\n\")\n",
    "optimal_model = model_list[3]\n",
    "model_topics = optimal_model.show_topics(formatted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_Num</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8658</td>\n",
       "      <td>movie, character, marvel, action, scene, mcu, ...</td>\n",
       "      <td>I ll start by saying that if you re looking fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.9822</td>\n",
       "      <td>movie, film, good, marvel, scene, character, f...</td>\n",
       "      <td>After 10 years of almost every movie being.arm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.7452</td>\n",
       "      <td>movie, film, good, marvel, scene, character, f...</td>\n",
       "      <td>A -BIG- Screen Mini Review. Viewed Sept.05, 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.9006</td>\n",
       "      <td>movie, film, good, marvel, scene, character, f...</td>\n",
       "      <td>Perfect Fantasy film to watch with full family...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.8611</td>\n",
       "      <td>movie, film, good, marvel, scene, character, f...</td>\n",
       "      <td>Keeping it short. This movie had it all. Great...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.9865</td>\n",
       "      <td>movie, film, good, marvel, scene, character, f...</td>\n",
       "      <td>Brought to you by the Truth Tellers.Film is gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.9701</td>\n",
       "      <td>movie, film, good, marvel, scene, character, f...</td>\n",
       "      <td>Haven t been much of a Marvel guy even with th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.9872</td>\n",
       "      <td>movie, film, good, marvel, scene, character, f...</td>\n",
       "      <td>I had very few expectations from this one, giv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.9212</td>\n",
       "      <td>movie, character, marvel, action, scene, mcu, ...</td>\n",
       "      <td>Shang-Chi and the Legend of the Ten Rings is a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.9922</td>\n",
       "      <td>movie, film, good, marvel, scene, character, f...</td>\n",
       "      <td>First off, this is a decent movie.Sure, there ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Document_Num  Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "0             0             3.0              0.8658   \n",
       "1             1             2.0              0.9822   \n",
       "2             2             2.0              0.7452   \n",
       "3             3             2.0              0.9006   \n",
       "4             4             2.0              0.8611   \n",
       "5             5             2.0              0.9865   \n",
       "6             6             2.0              0.9701   \n",
       "7             7             2.0              0.9872   \n",
       "8             8             3.0              0.9212   \n",
       "9             9             2.0              0.9922   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  movie, character, marvel, action, scene, mcu, ...   \n",
       "1  movie, film, good, marvel, scene, character, f...   \n",
       "2  movie, film, good, marvel, scene, character, f...   \n",
       "3  movie, film, good, marvel, scene, character, f...   \n",
       "4  movie, film, good, marvel, scene, character, f...   \n",
       "5  movie, film, good, marvel, scene, character, f...   \n",
       "6  movie, film, good, marvel, scene, character, f...   \n",
       "7  movie, film, good, marvel, scene, character, f...   \n",
       "8  movie, character, marvel, action, scene, mcu, ...   \n",
       "9  movie, film, good, marvel, scene, character, f...   \n",
       "\n",
       "                                                Text  \n",
       "0  I ll start by saying that if you re looking fo...  \n",
       "1  After 10 years of almost every movie being.arm...  \n",
       "2  A -BIG- Screen Mini Review. Viewed Sept.05, 20...  \n",
       "3  Perfect Fantasy film to watch with full family...  \n",
       "4  Keeping it short. This movie had it all. Great...  \n",
       "5  Brought to you by the Truth Tellers.Film is gr...  \n",
       "6  Haven t been much of a Marvel guy even with th...  \n",
       "7  I had very few expectations from this one, giv...  \n",
       "8  Shang-Chi and the Legend of the Ten Rings is a...  \n",
       "9  First off, this is a decent movie.Sure, there ...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_topics_sentences(ldamodel=LDA_model, corpus=corpus, texts=data):\n",
    "    \"\"\"\n",
    "    Input: LDA_model, corpus, reviews\n",
    "    Func: to extract keywords from each review topic wise with coherence score\n",
    "    Output: pandas dataframe\n",
    "    \"\"\"\n",
    "    output_df = pd.DataFrame()\n",
    "\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                output_df = output_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    output_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    output_df = pd.concat([output_df, contents], axis=1)\n",
    "    return (output_df)\n",
    "\n",
    "review_keywords = format_topics_sentences(ldamodel=optimal_model, corpus=corpus, texts=data) # Formatinf the reviews df with keywords\n",
    "\n",
    "\n",
    "df_dominant_topic = review_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_Num', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "\n",
    "# Show\n",
    "df_dominant_topic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_Num</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9974</td>\n",
       "      <td>movie, marvel, good, film, great, action, stor...</td>\n",
       "      <td>Shang-Chi is a movie that nobody expected. An ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9952</td>\n",
       "      <td>movie, marvel, character, film, well, good, se...</td>\n",
       "      <td>What more do you want?I honestly didn t want t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>movie, film, good, marvel, scene, character, f...</td>\n",
       "      <td>When Iron Man hit theatres back in 2008, there...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.9953</td>\n",
       "      <td>movie, character, marvel, action, scene, mcu, ...</td>\n",
       "      <td>Overall, the movie was worth a watch. A lot of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic_Num  Topic_Perc_Contrib  \\\n",
       "0        0.0              0.9974   \n",
       "1        1.0              0.9952   \n",
       "2        2.0              0.9970   \n",
       "3        3.0              0.9953   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  movie, marvel, good, film, great, action, stor...   \n",
       "1  movie, marvel, character, film, well, good, se...   \n",
       "2  movie, film, good, marvel, scene, character, f...   \n",
       "3  movie, character, marvel, action, scene, mcu, ...   \n",
       "\n",
       "                                                Text  \n",
       "0  Shang-Chi is a movie that nobody expected. An ...  \n",
       "1  What more do you want?I honestly didn t want t...  \n",
       "2  When Iron Man hit theatres back in 2008, there...  \n",
       "3  Overall, the movie was worth a watch. A lot of...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group top 5 sentences along with topic\n",
    "sorted_reviews = pd.DataFrame()\n",
    "\n",
    "sent_topics_outdf_grpd = review_keywords.groupby('Dominant_Topic')\n",
    "\n",
    "for i, grp in sent_topics_outdf_grpd:\n",
    "    sorted_reviews = pd.concat([sorted_reviews, \n",
    "                                             grp.sort_values(['Perc_Contribution'], ascending=[0]).head(1)], axis=0)   \n",
    "sorted_reviews.reset_index(drop=True, inplace=True)\n",
    "sorted_reviews.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Text\"]\n",
    "\n",
    "sorted_reviews.to_csv(\"Review_Topic.CSV\", index= False)\n",
    "sorted_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) (15 points) Generate K topics by using LSA, the number of topics K should be decided by the coherence score, then summarize what are the topics. You may refer the code here:\n",
    "\n",
    "https://www.datacamp.com/community/tutorials/discovering-hidden-topics-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lsa_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "    Dictionary of words freq --> dict\n",
    "    corpus of words --> list\n",
    "    reviews --> list\n",
    "    limit --> int\n",
    "    start --> int\n",
    "    step --> int\n",
    "    Func: find the coherence score for each set of topic numbers\n",
    "    Output: \n",
    "    model_list --> list: list of models\n",
    "    coherence_values --> float: score of coherence\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = LsiModel(corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSA_model = LsiModel(corpus=corpus, id2word=id2word, chunksize=100)\n",
    "review_lsa = LSA_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSA Coherence Score:  0.2280469429409865\n"
     ]
    }
   ],
   "source": [
    "coherence_model_lda = CoherenceModel(model=LSA_model, texts=lemmatize_reviews, dictionary=id2word, coherence='c_v') #initilize coherence model\n",
    "coherence_lda = coherence_model_lda.get_coherence() #get cohernece score\n",
    "print('LSA Coherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa_model_list, lsa_coherence_values = compute_lsa_coherence_values(dictionary=id2word, corpus=corpus, texts=lemmatize_reviews, start=1, limit=20, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics Number= 1  has Coherence Value of 0.3166\n",
      "Topics Number= 2  has Coherence Value of 0.3113\n",
      "Topics Number= 3  has Coherence Value of 0.3206\n",
      "Topics Number= 4  has Coherence Value of 0.3052\n",
      "Topics Number= 5  has Coherence Value of 0.3326\n",
      "Topics Number= 6  has Coherence Value of 0.337\n",
      "Topics Number= 7  has Coherence Value of 0.3321\n",
      "Topics Number= 8  has Coherence Value of 0.3213\n",
      "Topics Number= 9  has Coherence Value of 0.3176\n",
      "Topics Number= 10  has Coherence Value of 0.3219\n",
      "Topics Number= 11  has Coherence Value of 0.3119\n",
      "Topics Number= 12  has Coherence Value of 0.3114\n",
      "Topics Number= 13  has Coherence Value of 0.3175\n",
      "Topics Number= 14  has Coherence Value of 0.3132\n",
      "Topics Number= 15  has Coherence Value of 0.3217\n",
      "Topics Number= 16  has Coherence Value of 0.3169\n",
      "Topics Number= 17  has Coherence Value of 0.3099\n",
      "Topics Number= 18  has Coherence Value of 0.3135\n",
      "Topics Number= 19  has Coherence Value of 0.3003\n"
     ]
    }
   ],
   "source": [
    "for model, cv in zip(range(1, 20, 1), lsa_coherence_values):\n",
    "    print(\"Topics Number=\", model, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum value of coherence for ascending order is: 0.345\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Maximum value of coherence for ascending order is: 0.345\\n\")\n",
    "optimal_model = lsa_model_list[5]\n",
    "model_topics = optimal_model.show_topics(formatted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_Num</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5507</td>\n",
       "      <td>movie, film, marvel, character, well, good, sc...</td>\n",
       "      <td>I ll start by saying that if you re looking fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5361</td>\n",
       "      <td>movie, film, marvel, character, well, good, sc...</td>\n",
       "      <td>After 10 years of almost every movie being.arm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.9610</td>\n",
       "      <td>movie, film, marvel, character, well, good, sc...</td>\n",
       "      <td>A -BIG- Screen Mini Review. Viewed Sept.05, 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5555</td>\n",
       "      <td>film, marvel, character, movie, go, also, real...</td>\n",
       "      <td>Perfect Fantasy film to watch with full family...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.7966</td>\n",
       "      <td>movie, film, marvel, character, well, good, sc...</td>\n",
       "      <td>Keeping it short. This movie had it all. Great...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.5196</td>\n",
       "      <td>movie, film, marvel, character, well, good, sc...</td>\n",
       "      <td>Brought to you by the Truth Tellers.Film is gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.9423</td>\n",
       "      <td>movie, film, marvel, character, well, good, sc...</td>\n",
       "      <td>Haven t been much of a Marvel guy even with th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.1938</td>\n",
       "      <td>movie, film, marvel, character, well, good, sc...</td>\n",
       "      <td>I had very few expectations from this one, giv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.3782</td>\n",
       "      <td>movie, film, marvel, character, well, good, sc...</td>\n",
       "      <td>Shang-Chi and the Legend of the Ten Rings is a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.9951</td>\n",
       "      <td>movie, film, marvel, character, well, good, sc...</td>\n",
       "      <td>First off, this is a decent movie.Sure, there ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Document_Num  Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "0             0             0.0              3.5507   \n",
       "1             1             0.0              2.5361   \n",
       "2             2             0.0              9.9610   \n",
       "3             3             2.0              0.5555   \n",
       "4             4             0.0              3.7966   \n",
       "5             5             0.0              5.5196   \n",
       "6             6             0.0              1.9423   \n",
       "7             7             0.0              4.1938   \n",
       "8             8             0.0             12.3782   \n",
       "9             9             0.0              5.9951   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  movie, film, marvel, character, well, good, sc...   \n",
       "1  movie, film, marvel, character, well, good, sc...   \n",
       "2  movie, film, marvel, character, well, good, sc...   \n",
       "3  film, marvel, character, movie, go, also, real...   \n",
       "4  movie, film, marvel, character, well, good, sc...   \n",
       "5  movie, film, marvel, character, well, good, sc...   \n",
       "6  movie, film, marvel, character, well, good, sc...   \n",
       "7  movie, film, marvel, character, well, good, sc...   \n",
       "8  movie, film, marvel, character, well, good, sc...   \n",
       "9  movie, film, marvel, character, well, good, sc...   \n",
       "\n",
       "                                                Text  \n",
       "0  I ll start by saying that if you re looking fo...  \n",
       "1  After 10 years of almost every movie being.arm...  \n",
       "2  A -BIG- Screen Mini Review. Viewed Sept.05, 20...  \n",
       "3  Perfect Fantasy film to watch with full family...  \n",
       "4  Keeping it short. This movie had it all. Great...  \n",
       "5  Brought to you by the Truth Tellers.Film is gr...  \n",
       "6  Haven t been much of a Marvel guy even with th...  \n",
       "7  I had very few expectations from this one, giv...  \n",
       "8  Shang-Chi and the Legend of the Ten Rings is a...  \n",
       "9  First off, this is a decent movie.Sure, there ...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_topics_sentences(ldamodel=LSA_model, corpus=corpus, texts=data):\n",
    "    \"\"\"\n",
    "    Input: LDA_model, corpus, reviews\n",
    "    Func: to extract keywords from each review topic wise with coherence score\n",
    "    Output: pandas dataframe\n",
    "    \"\"\"\n",
    "    output_df = pd.DataFrame()\n",
    "\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                output_df = output_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    output_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    output_df = pd.concat([output_df, contents], axis=1)\n",
    "    return (output_df)\n",
    "\n",
    "review_keywords = format_topics_sentences(ldamodel=optimal_model, corpus=corpus, texts=data) # Formatinf the reviews df with keywords\n",
    "\n",
    "\n",
    "df_dominant_topic = review_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_Num', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "\n",
    "# Show\n",
    "df_dominant_topic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_Num</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>38.3054</td>\n",
       "      <td>movie, film, marvel, character, well, good, sc...</td>\n",
       "      <td>LikesGreat Pacing: Shang Chi has a lot of thin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.5644</td>\n",
       "      <td>movie, film, also, well, character, marvel, mc...</td>\n",
       "      <td>First of all, my husband and I love superhero ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.3977</td>\n",
       "      <td>film, marvel, character, movie, go, also, real...</td>\n",
       "      <td>Absolutely enjoyed the film from first to last...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.3399</td>\n",
       "      <td>marvel, mcu, great, scene, good, movie, really...</td>\n",
       "      <td>Oke I saw the suicide squat yesterday and just...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.4225</td>\n",
       "      <td>good, well, character, movie, marvel, feel, fi...</td>\n",
       "      <td>Total waste of time. Iron Man 2008 is so much ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>great, film, marvel, really, movie, character,...</td>\n",
       "      <td>Shang-Chi and the Legend of the Ten Rings  is...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic_Num  Topic_Perc_Contrib  \\\n",
       "0        0.0             38.3054   \n",
       "1        1.0              5.5644   \n",
       "2        2.0              1.3977   \n",
       "3        3.0              2.3399   \n",
       "4        4.0              0.4225   \n",
       "5        5.0              0.0000   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  movie, film, marvel, character, well, good, sc...   \n",
       "1  movie, film, also, well, character, marvel, mc...   \n",
       "2  film, marvel, character, movie, go, also, real...   \n",
       "3  marvel, mcu, great, scene, good, movie, really...   \n",
       "4  good, well, character, movie, marvel, feel, fi...   \n",
       "5  great, film, marvel, really, movie, character,...   \n",
       "\n",
       "                                                Text  \n",
       "0  LikesGreat Pacing: Shang Chi has a lot of thin...  \n",
       "1  First of all, my husband and I love superhero ...  \n",
       "2  Absolutely enjoyed the film from first to last...  \n",
       "3  Oke I saw the suicide squat yesterday and just...  \n",
       "4  Total waste of time. Iron Man 2008 is so much ...  \n",
       "5   Shang-Chi and the Legend of the Ten Rings  is...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group top 5 sentences along with topic\n",
    "sorted_reviews = pd.DataFrame()\n",
    "\n",
    "sent_topics_outdf_grpd = review_keywords.groupby('Dominant_Topic')\n",
    "\n",
    "for i, grp in sent_topics_outdf_grpd:\n",
    "    sorted_reviews = pd.concat([sorted_reviews, \n",
    "                                             grp.sort_values(['Perc_Contribution'], ascending=[0]).head(1)], axis=0)   \n",
    "sorted_reviews.reset_index(drop=True, inplace=True)\n",
    "sorted_reviews.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Text\"]\n",
    "\n",
    "sorted_reviews.to_csv(\"Review_Topic_LSA.CSV\", index= False)\n",
    "sorted_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) (10 points) Compare the results generated by the two topic modeling algorithms, which one is better? You should explain the reasons in details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here (no code needed for this question)\n",
    "\"\"\"\n",
    "LSA or you can say LSI is a much simple and fast method as compared to LDA. \n",
    "Purpose of both of them is same is to collect set of topics that can best describe the collections of sentences\n",
    "But!\n",
    "LSA is most simpller and only focus of frequency of words rether then there order. Although in some cases it can be a benifit but\n",
    "in our case this is not as such in favour of benifit. \n",
    "LDA is a bit complex and time taking algorithem but it do a deep analysis of the system and consider words as a sequence of words. \n",
    "and in our case it's seem a bit good as compared to LSA/LSI\n",
    "Coherence: LDA has high coherence value then LSA/LSI\n",
    "Topics: LDA gethered more useful topics and keyword collection then LSA/LSI\n",
    "Speed: LSA/LSI is much faster\n",
    "Text: the sorted text collected by LDA is better then that collected with LSA/LSI\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "11f1dc213e07634baa4c5c321dec03c05dafae643c50f20e6d1a492290c05dc2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
