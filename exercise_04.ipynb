{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "interpreter": {
      "hash": "11f1dc213e07634baa4c5c321dec03c05dafae643c50f20e6d1a492290c05dc2"
    },
    "kernelspec": {
      "display_name": "Python 3.9.6 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "name": "In_class_exercise_04.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaziunt2022/exercise_4/blob/main/exercise_04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpUI3n5HpaQI"
      },
      "source": [
        "# **The seventh in-class-exercise (40 points in total, 10/20/2021)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPu1TJjGpaQn"
      },
      "source": [
        "Question description: Please use the text corpus you collected in your last in-class-exercise for this exercise. Perform the following tasks:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ka7gDgJwpaQs"
      },
      "source": [
        "## (1) (15 points) Generate K topics by using LDA, the number of topics K should be decided by the coherence score, then summarize what are the topics. You may refer the code here: \n",
        "\n",
        "https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cknYzgQqpaQ0",
        "outputId": "9a23384b-b4e5-471d-d8e1-204fbce05c0b"
      },
      "source": [
        "# Write your code here\n",
        "# Write your code here\n",
        "# pip install pyLDAvis\n",
        "# pip install gensim\n",
        "# pip install spacy\n",
        "\n",
        "import nltk\n",
        "\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Gensim\n",
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models import CoherenceModel\n",
        "from gensim.models import LsiModel\n",
        "# spacy for lemmatization\n",
        "import spacy\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Enable logging for gensim - optional\n",
        "import logging\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
        "\n",
        "\n",
        "\n",
        "# Setting up nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "\n",
        "stop_words = stopwords.words('english')\n",
        "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bthX0ABdpaQ-"
      },
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/kaziunt2022/exercise_4/main/Reviews.CSV\") # Import the Reviews.CSV as pandas dataframe\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_NxbeBYpaRD"
      },
      "source": [
        "## Cleaning the reviews\n",
        "data = df.Reviews.values.tolist() # Convert each review to list\n",
        "data = [re.sub('\\s+', ' ', sentence) for sentence in data] # remose the line breakers\n",
        "data = [re.sub(\"\\'\",\" \", sentence) for sentence in data] # remocve the \\'\n",
        "\n",
        "def sent_to_words(reviews):\n",
        "    \"\"\"\n",
        "    Input: sentence--> string\n",
        "    Function: Tokenize the sentence and remove punctuations\n",
        "    Output: tokenize and clean reviews\n",
        "    \"\"\"\n",
        "    sentence = []\n",
        "    for review in reviews:\n",
        "        sentence.append(gensim.utils.simple_preprocess(str(review).encode('utf-8'), deacc=True))  # deacc=True removes punctuations\n",
        "    return sentence\n",
        "tokenize_reviews = list(sent_to_words(data))\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBrvDYxLpaRH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0461892-8bd8-4158-9eac-407e1e2e9aa9"
      },
      "source": [
        "## bigram and trigam mmodels \n",
        "bigram = gensim.models.Phrases(tokenize_reviews, min_count=5, threshold=100) # creat bigram phrases\n",
        "bigram_model = gensim.models.phrases.Phraser(bigram) # bigram model\n",
        "trigram_model = gensim.models.phrases.Phraser(gensim.models.Phrases(bigram[tokenize_reviews], threshold=100))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gV35kCbGpaRL"
      },
      "source": [
        "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
        "def remove_stopwords(reviews): \n",
        "    \"\"\"\n",
        "    Input: list of lists of reviews\n",
        "    Func: remove all stopwords\n",
        "    Output: tokenize reviews without stop words\n",
        "    \"\"\"\n",
        "    return [[word for word in simple_preprocess(str(review)) if word not in stop_words] for review in reviews]\n",
        "\n",
        "def make_bigrams(reviews):\n",
        "    \"\"\"\n",
        "    Input: tokenize reviews\n",
        "    Func: make bigrams\n",
        "    Output: bigrams of reviews\n",
        "    \"\"\"\n",
        "    return [bigram_model[review] for review in reviews]\n",
        "\n",
        "def make_trigrams(reviews):\n",
        "    \"\"\"\n",
        "    Input: tokenize reviews\n",
        "    Func: make trigrams\n",
        "    Output: trigrams of bigram reviews\n",
        "    \"\"\"\n",
        "    return [trigram_model[bigram_model[review]] for review in reviews]\n",
        "\n",
        "def lemmatization(reviews, allowed=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
        "    \"\"\"\n",
        "    Input: tokenize bigram reviews\n",
        "    Func: return only Noun, adj, verb, adverbs\n",
        "    Output: nouns, adj, verb, adv of reviews\n",
        "    \"\"\"\n",
        "    output_reviews= []\n",
        "    for sent in reviews:\n",
        "        review = nlp(\" \".join(sent)) \n",
        "        output_reviews.append([token.lemma_ for token in review if token.pos_ in allowed])\n",
        "    return output_reviews"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIHvIKoKpaRS"
      },
      "source": [
        "\n",
        "bigrame_reviews = make_bigrams(remove_stopwords(tokenize_reviews)) # take bigram of the Reviews without stopwords\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner']) # initiaize the nlp english model\n",
        "\n",
        "lemmatize_reviews = lemmatization(bigrame_reviews, ['NOUN', 'ADJ', 'VERB', 'ADV']) # nouns, adj, verb, adv of reviews\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfyfcrESpaRX"
      },
      "source": [
        "\n",
        "id2word = corpora.Dictionary(lemmatize_reviews) # Create Dictionary\n",
        "\n",
        "corpus = [id2word.doc2bow(review) for review in lemmatize_reviews] # freq of words\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsmqCK6kpaRq"
      },
      "source": [
        "# Create LDA model\n",
        "LDA_model = gensim.models.ldamodel.LdaModel(corpus=corpus, id2word=id2word, num_topics=20, random_state=100, update_every=1,\n",
        "                                            chunksize=100, passes=10, alpha='auto', per_word_topics=True)\n",
        "review_lda = LDA_model[corpus]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMRh3kuqpaRs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75268528-0947-4419-cb1f-58d30ea86ceb"
      },
      "source": [
        "print('Perplexity: ', LDA_model.log_perplexity(corpus))  # Compute Perplexity and print it\n",
        "coherence_model_lda = CoherenceModel(model=LDA_model, texts=lemmatize_reviews, dictionary=id2word, coherence='c_v') #initilize coherence model\n",
        "coherence_lda = coherence_model_lda.get_coherence() #get cohernece score\n",
        "print('Coherence Score: ', coherence_lda)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perplexity:  -7.234358997237455\n",
            "Coherence Score:  0.4799173353319075\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evBz7xzFpaRx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 665
        },
        "outputId": "10771f72-286a-485b-9d56-d8f1fcc62dd7"
      },
      "source": [
        "# Check and \n",
        "def get_lda_topics(model, num_topics):\n",
        "    \"\"\"\n",
        "    Input: LDA model, required topics\n",
        "    Func: create a dataframe of topics\n",
        "    Output: Pandas data frame\n",
        "    \"\"\"\n",
        "    word_dict = {}\n",
        "    for i in range(num_topics):\n",
        "        words = model.show_topic(i, topn = 20)\n",
        "        word_dict['Topic ' + '{:02d}'.format(i+1)] = [i[0] for i in words]\n",
        "    return pd.DataFrame(word_dict)\n",
        "\n",
        "get_lda_topics(LDA_model, 10)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic 01</th>\n",
              "      <th>Topic 02</th>\n",
              "      <th>Topic 03</th>\n",
              "      <th>Topic 04</th>\n",
              "      <th>Topic 05</th>\n",
              "      <th>Topic 06</th>\n",
              "      <th>Topic 07</th>\n",
              "      <th>Topic 08</th>\n",
              "      <th>Topic 09</th>\n",
              "      <th>Topic 10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>honest</td>\n",
              "      <td>major</td>\n",
              "      <td>problem</td>\n",
              "      <td>kill</td>\n",
              "      <td>kid</td>\n",
              "      <td>mother</td>\n",
              "      <td>graphic</td>\n",
              "      <td>film</td>\n",
              "      <td>feel</td>\n",
              "      <td>character</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>mediocre</td>\n",
              "      <td>effort</td>\n",
              "      <td>learn</td>\n",
              "      <td>run</td>\n",
              "      <td>due</td>\n",
              "      <td>wenwu</td>\n",
              "      <td>series</td>\n",
              "      <td>well</td>\n",
              "      <td>go</td>\n",
              "      <td>also</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>script</td>\n",
              "      <td>combine</td>\n",
              "      <td>woman</td>\n",
              "      <td>instead</td>\n",
              "      <td>die</td>\n",
              "      <td>power</td>\n",
              "      <td>small</td>\n",
              "      <td>plot</td>\n",
              "      <td>make</td>\n",
              "      <td>really</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>chop</td>\n",
              "      <td>cinematic</td>\n",
              "      <td>decide</td>\n",
              "      <td>train</td>\n",
              "      <td>theatre</td>\n",
              "      <td>particularly</td>\n",
              "      <td>flat</td>\n",
              "      <td>character</td>\n",
              "      <td>even</td>\n",
              "      <td>think</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>dangerous</td>\n",
              "      <td>influence</td>\n",
              "      <td>dark</td>\n",
              "      <td>wish</td>\n",
              "      <td>highly</td>\n",
              "      <td>bus</td>\n",
              "      <td>spend</td>\n",
              "      <td>little</td>\n",
              "      <td>see</td>\n",
              "      <td>much</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>landscape</td>\n",
              "      <td>score</td>\n",
              "      <td>connect</td>\n",
              "      <td>monster</td>\n",
              "      <td>sorry</td>\n",
              "      <td>attack</td>\n",
              "      <td>climax</td>\n",
              "      <td>bit</td>\n",
              "      <td>love</td>\n",
              "      <td>would</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>shake</td>\n",
              "      <td>shame</td>\n",
              "      <td>familiar</td>\n",
              "      <td>slow</td>\n",
              "      <td>ability</td>\n",
              "      <td>note</td>\n",
              "      <td>can</td>\n",
              "      <td>seem</td>\n",
              "      <td>way</td>\n",
              "      <td>thing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>high_expectation</td>\n",
              "      <td>crew</td>\n",
              "      <td>play</td>\n",
              "      <td>explain</td>\n",
              "      <td>dominate</td>\n",
              "      <td>death</td>\n",
              "      <td>vfx</td>\n",
              "      <td>overall</td>\n",
              "      <td>first</td>\n",
              "      <td>like</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>crap</td>\n",
              "      <td>let</td>\n",
              "      <td>master</td>\n",
              "      <td>exactly</td>\n",
              "      <td>exceptional</td>\n",
              "      <td>village</td>\n",
              "      <td>white</td>\n",
              "      <td>hero</td>\n",
              "      <td>character</td>\n",
              "      <td>main</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>brain</td>\n",
              "      <td>spot</td>\n",
              "      <td>other</td>\n",
              "      <td>reveal</td>\n",
              "      <td>shock</td>\n",
              "      <td>feature</td>\n",
              "      <td>damn</td>\n",
              "      <td>action</td>\n",
              "      <td>story</td>\n",
              "      <td>pretty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>winter_soldier</td>\n",
              "      <td>review</td>\n",
              "      <td>art</td>\n",
              "      <td>sister</td>\n",
              "      <td>game</td>\n",
              "      <td>sister</td>\n",
              "      <td>accept</td>\n",
              "      <td>always</td>\n",
              "      <td>lot</td>\n",
              "      <td>moment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>technically</td>\n",
              "      <td>male</td>\n",
              "      <td>soul</td>\n",
              "      <td>turn</td>\n",
              "      <td>timeline</td>\n",
              "      <td>mystical</td>\n",
              "      <td>thinking</td>\n",
              "      <td>sequence</td>\n",
              "      <td>chinese</td>\n",
              "      <td>ring</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>stage</td>\n",
              "      <td>everywhere</td>\n",
              "      <td>third_act</td>\n",
              "      <td>clear</td>\n",
              "      <td>talent</td>\n",
              "      <td>pendant</td>\n",
              "      <td>bored</td>\n",
              "      <td>quite</td>\n",
              "      <td>come</td>\n",
              "      <td>could</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>tiresome</td>\n",
              "      <td>sense</td>\n",
              "      <td>shoot</td>\n",
              "      <td>stuff</td>\n",
              "      <td>fase</td>\n",
              "      <td>thousand</td>\n",
              "      <td>mixed</td>\n",
              "      <td>role</td>\n",
              "      <td>time</td>\n",
              "      <td>place</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>slate</td>\n",
              "      <td>attractive</td>\n",
              "      <td>able</td>\n",
              "      <td>second</td>\n",
              "      <td>frequent</td>\n",
              "      <td>training</td>\n",
              "      <td>word</td>\n",
              "      <td>add</td>\n",
              "      <td>much</td>\n",
              "      <td>still</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>service</td>\n",
              "      <td>favor</td>\n",
              "      <td>save</td>\n",
              "      <td>find</td>\n",
              "      <td>willing</td>\n",
              "      <td>ancient</td>\n",
              "      <td>compound</td>\n",
              "      <td>keep</td>\n",
              "      <td>give</td>\n",
              "      <td>make</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>exception</td>\n",
              "      <td>brutal</td>\n",
              "      <td>mention</td>\n",
              "      <td>flashback</td>\n",
              "      <td>speed</td>\n",
              "      <td>childhood</td>\n",
              "      <td>overly</td>\n",
              "      <td>predictable</td>\n",
              "      <td>end</td>\n",
              "      <td>look</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>rather</td>\n",
              "      <td>suprise</td>\n",
              "      <td>beat</td>\n",
              "      <td>ridiculous</td>\n",
              "      <td>lame</td>\n",
              "      <td>lead</td>\n",
              "      <td>dog</td>\n",
              "      <td>especially</td>\n",
              "      <td>people</td>\n",
              "      <td>less</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>impossible</td>\n",
              "      <td>consequence</td>\n",
              "      <td>original</td>\n",
              "      <td>abomination</td>\n",
              "      <td>numerous</td>\n",
              "      <td>destroy</td>\n",
              "      <td>animate</td>\n",
              "      <td>interesting</td>\n",
              "      <td>get</td>\n",
              "      <td>cool</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>room</td>\n",
              "      <td>upset</td>\n",
              "      <td>cause</td>\n",
              "      <td>try</td>\n",
              "      <td>covid</td>\n",
              "      <td>moral</td>\n",
              "      <td>fictional</td>\n",
              "      <td>many</td>\n",
              "      <td>say</td>\n",
              "      <td>storyline</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Topic 01     Topic 02   Topic 03  ...     Topic 08   Topic 09   Topic 10\n",
              "0             honest        major    problem  ...         film       feel  character\n",
              "1           mediocre       effort      learn  ...         well         go       also\n",
              "2             script      combine      woman  ...         plot       make     really\n",
              "3               chop    cinematic     decide  ...    character       even      think\n",
              "4          dangerous    influence       dark  ...       little        see       much\n",
              "5          landscape        score    connect  ...          bit       love      would\n",
              "6              shake        shame   familiar  ...         seem        way      thing\n",
              "7   high_expectation         crew       play  ...      overall      first       like\n",
              "8               crap          let     master  ...         hero  character       main\n",
              "9              brain         spot      other  ...       action      story     pretty\n",
              "10    winter_soldier       review        art  ...       always        lot     moment\n",
              "11       technically         male       soul  ...     sequence    chinese       ring\n",
              "12             stage   everywhere  third_act  ...        quite       come      could\n",
              "13          tiresome        sense      shoot  ...         role       time      place\n",
              "14             slate   attractive       able  ...          add       much      still\n",
              "15           service        favor       save  ...         keep       give       make\n",
              "16         exception       brutal    mention  ...  predictable        end       look\n",
              "17            rather      suprise       beat  ...   especially     people       less\n",
              "18        impossible  consequence   original  ...  interesting        get       cool\n",
              "19              room        upset      cause  ...         many        say  storyline\n",
              "\n",
              "[20 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F07EfyR6paRz"
      },
      "source": [
        "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
        "    \"\"\"\n",
        "    Input: \n",
        "    Dictionary of words freq --> dict\n",
        "    corpus of words --> list\n",
        "    reviews --> list\n",
        "    limit --> int\n",
        "    start --> int\n",
        "    step --> int\n",
        "    Func: find the coherence score for each set of topic numbers\n",
        "    Output: \n",
        "    model_list --> list: list of models\n",
        "    coherence_values --> float: score of coherence\n",
        "    \"\"\"\n",
        "    coherence_values = []\n",
        "    model_list = []\n",
        "    for num_topics in range(start, limit, step):\n",
        "        model = gensim.models.LdaModel(corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
        "        model_list.append(model)\n",
        "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
        "        coherence_values.append(coherencemodel.get_coherence())\n",
        "\n",
        "    return model_list, coherence_values"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbRqzPpVpaR2"
      },
      "source": [
        "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=lemmatize_reviews, start=1, limit=20, step=1)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0dLqT51paR4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "778255fc-ce99-40a3-9f22-e67fc6f9a5d2"
      },
      "source": [
        "for model, cv in zip(range(1, 20, 1), coherence_values):\n",
        "    print(\"Topics Number=\", model, \" has Coherence Value of\", round(cv, 4))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topics Number= 1  has Coherence Value of 0.2977\n",
            "Topics Number= 2  has Coherence Value of 0.2933\n",
            "Topics Number= 3  has Coherence Value of 0.3038\n",
            "Topics Number= 4  has Coherence Value of 0.3013\n",
            "Topics Number= 5  has Coherence Value of 0.3106\n",
            "Topics Number= 6  has Coherence Value of 0.3127\n",
            "Topics Number= 7  has Coherence Value of 0.3035\n",
            "Topics Number= 8  has Coherence Value of 0.3041\n",
            "Topics Number= 9  has Coherence Value of 0.3076\n",
            "Topics Number= 10  has Coherence Value of 0.3016\n",
            "Topics Number= 11  has Coherence Value of 0.3087\n",
            "Topics Number= 12  has Coherence Value of 0.3062\n",
            "Topics Number= 13  has Coherence Value of 0.3162\n",
            "Topics Number= 14  has Coherence Value of 0.3132\n",
            "Topics Number= 15  has Coherence Value of 0.3054\n",
            "Topics Number= 16  has Coherence Value of 0.3053\n",
            "Topics Number= 17  has Coherence Value of 0.3052\n",
            "Topics Number= 18  has Coherence Value of 0.3021\n",
            "Topics Number= 19  has Coherence Value of 0.2969\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hZd3u-rpaR7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f44e999-ba6d-480c-f352-5f70d0b94f96"
      },
      "source": [
        "print(\"Maximum value of coherence for ascending order is: 0.3152\\n\")\n",
        "optimal_model = model_list[3]\n",
        "model_topics = optimal_model.show_topics(formatted=False)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum value of coherence for ascending order is: 0.3152\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScaF6xIBpaR9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "de98adeb-3b42-4be0-8e07-55171b5f467e"
      },
      "source": [
        "def format_topics_sentences(ldamodel=LDA_model, corpus=corpus, texts=data):\n",
        "    \"\"\"\n",
        "    Input: LDA_model, corpus, reviews\n",
        "    Func: to extract keywords from each review topic wise with coherence score\n",
        "    Output: pandas dataframe\n",
        "    \"\"\"\n",
        "    output_df = pd.DataFrame()\n",
        "\n",
        "    for i, row in enumerate(ldamodel[corpus]):\n",
        "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
        "        for j, (topic_num, prop_topic) in enumerate(row):\n",
        "            if j == 0:  # => dominant topic\n",
        "                wp = ldamodel.show_topic(topic_num)\n",
        "                topic_keywords = \", \".join([word for word, prop in wp])\n",
        "                output_df = output_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
        "            else:\n",
        "                break\n",
        "    output_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
        "\n",
        "    # Add original text to the end of the output\n",
        "    contents = pd.Series(texts)\n",
        "    output_df = pd.concat([output_df, contents], axis=1)\n",
        "    return (output_df)\n",
        "\n",
        "review_keywords = format_topics_sentences(ldamodel=optimal_model, corpus=corpus, texts=data) # Formatinf the reviews df with keywords\n",
        "\n",
        "\n",
        "df_dominant_topic = review_keywords.reset_index()\n",
        "df_dominant_topic.columns = ['Document_Num', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
        "\n",
        "# Show\n",
        "df_dominant_topic.head(10)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Document_Num</th>\n",
              "      <th>Dominant_Topic</th>\n",
              "      <th>Topic_Perc_Contrib</th>\n",
              "      <th>Keywords</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.9909</td>\n",
              "      <td>movie, good, film, marvel, great, story, scene...</td>\n",
              "      <td>I ll start by saying that if you re looking fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.9817</td>\n",
              "      <td>movie, film, character, good, really, scene, s...</td>\n",
              "      <td>After 10 years of almost every movie being.arm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.7684</td>\n",
              "      <td>movie, film, good, scene, make, marvel, charac...</td>\n",
              "      <td>A -BIG- Screen Mini Review. Viewed Sept.05, 20...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.8996</td>\n",
              "      <td>movie, film, action, character, story, good, w...</td>\n",
              "      <td>Perfect Fantasy film to watch with full family...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.4875</td>\n",
              "      <td>movie, good, film, marvel, great, story, scene...</td>\n",
              "      <td>Keeping it short. This movie had it all. Great...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.9848</td>\n",
              "      <td>movie, film, action, character, story, good, w...</td>\n",
              "      <td>Brought to you by the Truth Tellers.Film is gr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.6342</td>\n",
              "      <td>movie, film, character, good, really, scene, s...</td>\n",
              "      <td>Haven t been much of a Marvel guy even with th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.5973</td>\n",
              "      <td>movie, film, action, character, story, good, w...</td>\n",
              "      <td>I had very few expectations from this one, giv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.3959</td>\n",
              "      <td>movie, film, action, character, story, good, w...</td>\n",
              "      <td>Shang-Chi and the Legend of the Ten Rings is a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5154</td>\n",
              "      <td>movie, film, character, good, really, scene, s...</td>\n",
              "      <td>First off, this is a decent movie.Sure, there ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Document_Num  ...                                               Text\n",
              "0             0  ...  I ll start by saying that if you re looking fo...\n",
              "1             1  ...  After 10 years of almost every movie being.arm...\n",
              "2             2  ...  A -BIG- Screen Mini Review. Viewed Sept.05, 20...\n",
              "3             3  ...  Perfect Fantasy film to watch with full family...\n",
              "4             4  ...  Keeping it short. This movie had it all. Great...\n",
              "5             5  ...  Brought to you by the Truth Tellers.Film is gr...\n",
              "6             6  ...  Haven t been much of a Marvel guy even with th...\n",
              "7             7  ...  I had very few expectations from this one, giv...\n",
              "8             8  ...  Shang-Chi and the Legend of the Ten Rings is a...\n",
              "9             9  ...  First off, this is a decent movie.Sure, there ...\n",
              "\n",
              "[10 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hk7prhTLpaSA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "outputId": "2c93e9d4-6bc6-4db2-a2cf-8865ab8a5ab7"
      },
      "source": [
        "# Group top 5 sentences along with topic\n",
        "sorted_reviews = pd.DataFrame()\n",
        "\n",
        "sent_topics_outdf_grpd = review_keywords.groupby('Dominant_Topic')\n",
        "\n",
        "for i, grp in sent_topics_outdf_grpd:\n",
        "    sorted_reviews = pd.concat([sorted_reviews, \n",
        "                                             grp.sort_values(['Perc_Contribution'], ascending=[0]).head(1)], axis=0)   \n",
        "sorted_reviews.reset_index(drop=True, inplace=True)\n",
        "sorted_reviews.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Text\"]\n",
        "\n",
        "sorted_reviews.to_csv(\"Review_Topic.CSV\", index= False)\n",
        "sorted_reviews"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic_Num</th>\n",
              "      <th>Topic_Perc_Contrib</th>\n",
              "      <th>Keywords</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9973</td>\n",
              "      <td>movie, film, good, scene, make, marvel, charac...</td>\n",
              "      <td>Shang-Chi is a movie that nobody expected. An ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.9938</td>\n",
              "      <td>movie, film, character, good, really, scene, s...</td>\n",
              "      <td>WOW! This movie wasn t bad at all...-the actio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.9949</td>\n",
              "      <td>movie, film, action, character, story, good, w...</td>\n",
              "      <td>This movie is a blast and then some. It is, ju...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.9971</td>\n",
              "      <td>movie, good, film, marvel, great, story, scene...</td>\n",
              "      <td>Shang-Chi and the Legend of the Ten Rings is a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Topic_Num  ...                                               Text\n",
              "0        0.0  ...  Shang-Chi is a movie that nobody expected. An ...\n",
              "1        1.0  ...  WOW! This movie wasn t bad at all...-the actio...\n",
              "2        2.0  ...  This movie is a blast and then some. It is, ju...\n",
              "3        3.0  ...  Shang-Chi and the Legend of the Ten Rings is a...\n",
              "\n",
              "[4 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reb5-29ipaSD"
      },
      "source": [
        "## (2) (15 points) Generate K topics by using LSA, the number of topics K should be decided by the coherence score, then summarize what are the topics. You may refer the code here:\n",
        "\n",
        "https://www.datacamp.com/community/tutorials/discovering-hidden-topics-python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtKRJMSRpaSF"
      },
      "source": [
        "def compute_lsa_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
        "    \"\"\"\n",
        "    Input: \n",
        "    Dictionary of words freq --> dict\n",
        "    corpus of words --> list\n",
        "    reviews --> list\n",
        "    limit --> int\n",
        "    start --> int\n",
        "    step --> int\n",
        "    Func: find the coherence score for each set of topic numbers\n",
        "    Output: \n",
        "    model_list --> list: list of models\n",
        "    coherence_values --> float: score of coherence\n",
        "    \"\"\"\n",
        "    coherence_values = []\n",
        "    model_list = []\n",
        "    for num_topics in range(start, limit, step):\n",
        "        model = LsiModel(corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
        "        model_list.append(model)\n",
        "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
        "        coherence_values.append(coherencemodel.get_coherence())\n",
        "\n",
        "    return model_list, coherence_values\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWJmHhGmpaSH"
      },
      "source": [
        "LSA_model = LsiModel(corpus=corpus, id2word=id2word, chunksize=100)\n",
        "review_lsa = LSA_model[corpus]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIoOGcmBpaSI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "123403bf-32d1-4b6e-808d-2a4bdb90e5ce"
      },
      "source": [
        "coherence_model_lda = CoherenceModel(model=LSA_model, texts=lemmatize_reviews, dictionary=id2word, coherence='c_v') #initilize coherence model\n",
        "coherence_lda = coherence_model_lda.get_coherence() #get cohernece score\n",
        "print('LSA Coherence Score: ', coherence_lda)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSA Coherence Score:  0.23793908340553266\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5H0KyvYpaSK"
      },
      "source": [
        "lsa_model_list, lsa_coherence_values = compute_lsa_coherence_values(dictionary=id2word, corpus=corpus, texts=lemmatize_reviews, start=1, limit=20, step=1)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PXFKmkypaSL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb4adc8f-be0b-4781-c7bd-7de958669101"
      },
      "source": [
        "for model, cv in zip(range(1, 20, 1), lsa_coherence_values):\n",
        "    print(\"Topics Number=\", model, \" has Coherence Value of\", round(cv, 4))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topics Number= 1  has Coherence Value of 0.3025\n",
            "Topics Number= 2  has Coherence Value of 0.3306\n",
            "Topics Number= 3  has Coherence Value of 0.3252\n",
            "Topics Number= 4  has Coherence Value of 0.3704\n",
            "Topics Number= 5  has Coherence Value of 0.3533\n",
            "Topics Number= 6  has Coherence Value of 0.33\n",
            "Topics Number= 7  has Coherence Value of 0.3486\n",
            "Topics Number= 8  has Coherence Value of 0.3549\n",
            "Topics Number= 9  has Coherence Value of 0.3396\n",
            "Topics Number= 10  has Coherence Value of 0.3408\n",
            "Topics Number= 11  has Coherence Value of 0.3415\n",
            "Topics Number= 12  has Coherence Value of 0.3317\n",
            "Topics Number= 13  has Coherence Value of 0.3245\n",
            "Topics Number= 14  has Coherence Value of 0.3306\n",
            "Topics Number= 15  has Coherence Value of 0.3288\n",
            "Topics Number= 16  has Coherence Value of 0.3327\n",
            "Topics Number= 17  has Coherence Value of 0.3273\n",
            "Topics Number= 18  has Coherence Value of 0.3264\n",
            "Topics Number= 19  has Coherence Value of 0.3233\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CT87q2g3paSN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04d08143-fc83-4ea6-9346-f67682bd4323"
      },
      "source": [
        "print(\"Maximum value of coherence for ascending order is: 0.345\\n\")\n",
        "optimal_model = lsa_model_list[5]\n",
        "model_topics = optimal_model.show_topics(formatted=False)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum value of coherence for ascending order is: 0.345\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHd6HL-spaSP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "17c71342-23d9-410b-e936-7a43fa2e9551"
      },
      "source": [
        "def format_topics_sentences(ldamodel=LSA_model, corpus=corpus, texts=data):\n",
        "    \"\"\"\n",
        "    Input: LDA_model, corpus, reviews\n",
        "    Func: to extract keywords from each review topic wise with coherence score\n",
        "    Output: pandas dataframe\n",
        "    \"\"\"\n",
        "    output_df = pd.DataFrame()\n",
        "\n",
        "    for i, row in enumerate(ldamodel[corpus]):\n",
        "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
        "        for j, (topic_num, prop_topic) in enumerate(row):\n",
        "            if j == 0:  # => dominant topic\n",
        "                wp = ldamodel.show_topic(topic_num)\n",
        "                topic_keywords = \", \".join([word for word, prop in wp])\n",
        "                output_df = output_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
        "            else:\n",
        "                break\n",
        "    output_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
        "\n",
        "    # Add original text to the end of the output\n",
        "    contents = pd.Series(texts)\n",
        "    output_df = pd.concat([output_df, contents], axis=1)\n",
        "    return (output_df)\n",
        "\n",
        "review_keywords = format_topics_sentences(ldamodel=optimal_model, corpus=corpus, texts=data) # Formatinf the reviews df with keywords\n",
        "\n",
        "\n",
        "df_dominant_topic = review_keywords.reset_index()\n",
        "df_dominant_topic.columns = ['Document_Num', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
        "\n",
        "# Show\n",
        "df_dominant_topic.head(10)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Document_Num</th>\n",
              "      <th>Dominant_Topic</th>\n",
              "      <th>Topic_Perc_Contrib</th>\n",
              "      <th>Keywords</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.4973</td>\n",
              "      <td>movie, film, character, good, scene, marvel, a...</td>\n",
              "      <td>I ll start by saying that if you re looking fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.4708</td>\n",
              "      <td>movie, film, character, good, scene, marvel, a...</td>\n",
              "      <td>After 10 years of almost every movie being.arm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.6877</td>\n",
              "      <td>movie, film, character, good, scene, marvel, a...</td>\n",
              "      <td>A -BIG- Screen Mini Review. Viewed Sept.05, 20...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5860</td>\n",
              "      <td>movie, film, also, character, well, great, mar...</td>\n",
              "      <td>Perfect Fantasy film to watch with full family...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.5984</td>\n",
              "      <td>movie, film, character, good, scene, marvel, a...</td>\n",
              "      <td>Keeping it short. This movie had it all. Great...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0371</td>\n",
              "      <td>movie, film, character, good, scene, marvel, a...</td>\n",
              "      <td>Brought to you by the Truth Tellers.Film is gr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.7666</td>\n",
              "      <td>movie, film, character, good, scene, marvel, a...</td>\n",
              "      <td>Haven t been much of a Marvel guy even with th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.8181</td>\n",
              "      <td>movie, film, character, good, scene, marvel, a...</td>\n",
              "      <td>I had very few expectations from this one, giv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.5677</td>\n",
              "      <td>movie, film, character, good, scene, marvel, a...</td>\n",
              "      <td>Shang-Chi and the Legend of the Ten Rings is a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.8153</td>\n",
              "      <td>movie, film, character, good, scene, marvel, a...</td>\n",
              "      <td>First off, this is a decent movie.Sure, there ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Document_Num  ...                                               Text\n",
              "0             0  ...  I ll start by saying that if you re looking fo...\n",
              "1             1  ...  After 10 years of almost every movie being.arm...\n",
              "2             2  ...  A -BIG- Screen Mini Review. Viewed Sept.05, 20...\n",
              "3             3  ...  Perfect Fantasy film to watch with full family...\n",
              "4             4  ...  Keeping it short. This movie had it all. Great...\n",
              "5             5  ...  Brought to you by the Truth Tellers.Film is gr...\n",
              "6             6  ...  Haven t been much of a Marvel guy even with th...\n",
              "7             7  ...  I had very few expectations from this one, giv...\n",
              "8             8  ...  Shang-Chi and the Legend of the Ten Rings is a...\n",
              "9             9  ...  First off, this is a decent movie.Sure, there ...\n",
              "\n",
              "[10 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NV7snpTzpaSS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "outputId": "768ecda2-c902-4804-ee56-8bdaf5bf8524"
      },
      "source": [
        "# Group top 5 sentences along with topic\n",
        "sorted_reviews = pd.DataFrame()\n",
        "\n",
        "sent_topics_outdf_grpd = review_keywords.groupby('Dominant_Topic')\n",
        "\n",
        "for i, grp in sent_topics_outdf_grpd:\n",
        "    sorted_reviews = pd.concat([sorted_reviews, \n",
        "                                             grp.sort_values(['Perc_Contribution'], ascending=[0]).head(1)], axis=0)   \n",
        "sorted_reviews.reset_index(drop=True, inplace=True)\n",
        "sorted_reviews.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Text\"]\n",
        "\n",
        "sorted_reviews.to_csv(\"Review_Topic_LSA.CSV\", index= False)\n",
        "sorted_reviews"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic_Num</th>\n",
              "      <th>Topic_Perc_Contrib</th>\n",
              "      <th>Keywords</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>36.1684</td>\n",
              "      <td>movie, film, character, good, scene, marvel, a...</td>\n",
              "      <td>LikesGreat Pacing: Shang Chi has a lot of thin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>11.7483</td>\n",
              "      <td>movie, film, also, character, well, great, mar...</td>\n",
              "      <td>Marvel Studios has gained a glamorous reputati...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.0</td>\n",
              "      <td>16.2544</td>\n",
              "      <td>film, movie, character, go, also, really, woul...</td>\n",
              "      <td>I went to watch Shang-Chi and the Legend of th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.0</td>\n",
              "      <td>3.4255</td>\n",
              "      <td>good, scene, well, fight, movie, great, also, ...</td>\n",
              "      <td>Leung s acting was superb. So good that others...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.0</td>\n",
              "      <td>0.9076</td>\n",
              "      <td>great, really, well, character, film, go, acti...</td>\n",
              "      <td>WoW!!! Spectacular viewing from the MCU!Sean (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0.7392</td>\n",
              "      <td>good, scene, marvel, action, story, fight, fee...</td>\n",
              "      <td>This was by far the most boring MCU title I ve...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Topic_Num  ...                                               Text\n",
              "0        0.0  ...  LikesGreat Pacing: Shang Chi has a lot of thin...\n",
              "1        1.0  ...  Marvel Studios has gained a glamorous reputati...\n",
              "2        2.0  ...  I went to watch Shang-Chi and the Legend of th...\n",
              "3        3.0  ...  Leung s acting was superb. So good that others...\n",
              "4        4.0  ...  WoW!!! Spectacular viewing from the MCU!Sean (...\n",
              "5        5.0  ...  This was by far the most boring MCU title I ve...\n",
              "\n",
              "[6 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcEacGGypaSU"
      },
      "source": [
        "## (3) (10 points) Compare the results generated by the two topic modeling algorithms, which one is better? You should explain the reasons in details."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xATLaJHUpaSV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "70508645-23a0-4a8b-9e44-6538488126b9"
      },
      "source": [
        "# Write your answer here (no code needed for this question)\n",
        "\"\"\"\n",
        "LSA or you can say LSI is a much simple and fast method as compared to LDA. \n",
        "Purpose of both of them is same is to collect set of topics that can best describe the collections of sentences\n",
        "But!\n",
        "LSA is most simpller and only focus of frequency of words rether then there order. Although in some cases it can be a benifit but\n",
        "in our case this is not as such in favour of benifit. \n",
        "LDA is a bit complex and time taking algorithem but it do a deep analysis of the system and consider words as a sequence of words. \n",
        "and in our case it's seem a bit good as compared to LSA/LSI\n",
        "Coherence: LDA has high coherence value then LSA/LSI\n",
        "Topics: LDA gethered more useful topics and keyword collection then LSA/LSI\n",
        "Speed: LSA/LSI is much faster\n",
        "Text: the sorted text collected by LDA is better then that collected with LSA/LSI\n",
        "\"\"\""
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nLSA or you can say LSI is a much simple and fast method as compared to LDA. \\nPurpose of both of them is same is to collect set of topics that can best describe the collections of sentences\\nBut!\\nLSA is most simpller and only focus of frequency of words rether then there order. Although in some cases it can be a benifit but\\nin our case this is not as such in favour of benifit. \\nLDA is a bit complex and time taking algorithem but it do a deep analysis of the system and consider words as a sequence of words. \\nand in our case it's seem a bit good as compared to LSA/LSI\\nCoherence: LDA has high coherence value then LSA/LSI\\nTopics: LDA gethered more useful topics and keyword collection then LSA/LSI\\nSpeed: LSA/LSI is much faster\\nText: the sorted text collected by LDA is better then that collected with LSA/LSI\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    }
  ]
}